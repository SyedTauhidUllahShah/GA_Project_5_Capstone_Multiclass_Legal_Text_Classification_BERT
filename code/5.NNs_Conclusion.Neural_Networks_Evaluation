{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install --upgrade pip`\n",
    "\n",
    "`pip install Keras`\n",
    "\n",
    "`pip install tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../data/df_clean_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clause_text</th>\n",
       "      <th>clause_type</th>\n",
       "      <th>clause_word_count</th>\n",
       "      <th>bag_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>9741</td>\n",
       "      <td>In the performance of such services as describ...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>performance services described insurer shall c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9742</th>\n",
       "      <td>9742</td>\n",
       "      <td>It shall comply with all applicable laws relat...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>shall comply applicable laws relating performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9743</th>\n",
       "      <td>9743</td>\n",
       "      <td>JCR agrees to comply with all applicable laws,...</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>jcr agrees comply applicable laws rules regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>9744</td>\n",
       "      <td>Landlord and Tenant shall each do all acts nec...</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>landlord tenant shall acts necessary comply ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9745</th>\n",
       "      <td>9745</td>\n",
       "      <td>Licensee acknowledges that this Agreement does...</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>licensee acknowledges agreement constitute lic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                        clause_text  \\\n",
       "9741        9741  In the performance of such services as describ...   \n",
       "9742        9742  It shall comply with all applicable laws relat...   \n",
       "9743        9743  JCR agrees to comply with all applicable laws,...   \n",
       "9744        9744  Landlord and Tenant shall each do all acts nec...   \n",
       "9745        9745  Licensee acknowledges that this Agreement does...   \n",
       "\n",
       "      clause_type  clause_word_count  \\\n",
       "9741            2                 19   \n",
       "9742            2                 14   \n",
       "9743            2                 23   \n",
       "9744            2                 43   \n",
       "9745            2                 90   \n",
       "\n",
       "                                       bag_cleaned_text  \n",
       "9741  performance services described insurer shall c...  \n",
       "9742  shall comply applicable laws relating performa...  \n",
       "9743  jcr agrees comply applicable laws rules regula...  \n",
       "9744  landlord tenant shall acts necessary comply ap...  \n",
       "9745  licensee acknowledges agreement constitute lic...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_other_nulls = df[pd.isnull(df['bag_cleaned_text'])].index.tolist()\n",
    "df = df.drop(check_other_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the data \n",
    "vocabulary_size = 500000\n",
    "max_sequence = 500\n",
    "embedding_dim = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['bag_cleaned_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12475 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(df[\"bag_cleaned_text\"].values)\n",
    "X = pad_sequences(X, maxlen= max_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9741, 500)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target: (9741,)\n"
     ]
    }
   ],
   "source": [
    "y = df[\"clause_type\"]\n",
    "print('Shape of target:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7792, 500) (7792,)\n",
      "(1949, 500) (1949,)\n"
     ]
    }
   ],
   "source": [
    "#Train_test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grahamlim/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2995: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "pt = PowerTransformer()\n",
    "X_train_pt = pt.fit_transform(X_train)\n",
    "X_test_pt = pt.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 1.5871 - mean_absolute_error: 1.5873 - val_loss: 1.5999 - val_mean_absolute_error: 1.5962\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 48s 3s/step - loss: 1.5876 - mean_absolute_error: 1.5873 - val_loss: 1.5999 - val_mean_absolute_error: 1.5962\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 52s 4s/step - loss: 1.5874 - mean_absolute_error: 1.5873 - val_loss: 1.5999 - val_mean_absolute_error: 1.5962\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 1.5876 - mean_absolute_error: 1.5873 - val_loss: 1.5999 - val_mean_absolute_error: 1.5962\n"
     ]
    }
   ],
   "source": [
    "#building model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocabulary_size, embedding_dim))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(embedding_dim)))\n",
    "\n",
    "model.add(Dense(1200, activation = 'relu', input_shape = (500,)))\n",
    "\n",
    "model.add(Dense(600, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(300, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(120, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(32, activation = 'relu' ))\n",
    "\n",
    "model.add(Dense(12, activation = 'relu' ))\n",
    "\n",
    "#output layer \n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#adjust learning rate\n",
    "# adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adam = optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0001, amsgrad=False)\n",
    "# RMSprop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer= adam, loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('mean_absolute_error')\n",
    "plt.plot(history.history['mean_absolute_error'], label='train')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The maximum number of words to be used. (most frequent)\n",
    "# MAX_NB_WORDS = 1200000\n",
    "# # Max number of words in each clause.\n",
    "# MAX_SEQUENCE_LENGTH = 500\n",
    "# # This is fixed.\n",
    "# EMBEDDING_DIM = 100\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Bidirectional(LSTM(EMBEDDING_DIM)))\n",
    "# model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer=opt,\n",
    "#               metrics=['accuracy'],)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     epochs=num_epochs, \n",
    "#                     validation_data=(X_test, y_test), \n",
    "#                     verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "# model.add(SpatialDropout1D(0.2))\n",
    "# model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
